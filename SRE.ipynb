{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5011df8-fd48-4ebc-900f-1a55c4743dd2",
   "metadata": {},
   "source": [
    "## Incident Call Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b383723b-cb34-4a85-b46e-9499f5912d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet openai-whisper\n",
    "%pip install --quiet git+https://github.com/huggingface/transformers ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3865ffa-f478-4e10-89a2-d75641147880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\",\"openai/whisper-large-v3\",torch_dtype=torch.float16,device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70397c3a-7735-41b4-9972-c1d91c48cbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qasim/anaconda3/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed task=translate, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=translate.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "res = pipe('./Video-20240528_065110-Meeting Recording.mp4', generate_kwargs={\"language\": \"fa\",\"task\":\"translate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeaddd9b-ab34-446e-9e41-953b683c8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" can you hear me? yes, I can hear you can you hear me? yes I can hear you, my friend, can you hear me? yes, I can hear you yes, I can hear you I'm listening, what's the problem? I think my voice is too loud I think I have a connection. I have a soft RAM in draw. Yeah, I mean it's asking which database has problems. So, Sayed Hussain maybe. Ramin, we have been working on the maximum number of users in the database, and we have been dealing with issues with the Goldchain user. I have reduced the number of feet to 20 now, but the load has increased, and we need more users. Can you check how is the base? We connect proxy SQL 10G to B I will send the address to the same group I checked it now Look guys I was checking proxy SQL B The number of users that were connected was a lot, but it was not reached to the end. Let me tell you. So now it has reached the maximum? No, it has not reached the maximum of 1000. For example, 800 of them will reach and come down. Let me see what's happening. one second please, it's 75 Look, it's only 75, 75 is not enough, I look at the pool Now you have 20 connections, master itself has 8 connections, you don't have more than one connection Let me look at the rest I had the internet on the command for a while, I was so busy that I was busy, but let me see how it is Can we turn up the back-end? You have 3000 connections on these 3 Do you check the connection of the RIPO? I'm checking the RIPER on the CLUT Let me check the RIPER I'm going to make a I can also reduce the number of batches You can reduce it, but I can't do it at the same time as Ramin. I can't do it more than one level. And the point is that I can reduce the number of memory on this thing. I have reduced the number of steps on the second page. I will monitor it and if it is ok, I will reduce the number of steps to 100. Now it is 110. Each step has 900 mCa CPU. I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I will try to make it as smooth as possible I'm not sure if I should use the right one I will see if I can see this for a moment I will see if I can see this for a moment I will share my page with you I hope that the internet will not be a problem I will see if there are any users here Since we didn't change the path and all that, has our load increased? In this photo, the connection has increased, but has our load increased or has the service been reloaded? I think it's in May. The service hasn't been changed from the beginning. I mean, they haven't taken a degree from us. But the students from Mani, I think they had some changes. They gave them yesterday, and I think they gave them again today. I'll let the audience talk. I think Mohammad is here. Who is the other guy? Mohammad was in the call now. Let me call him. Ok. Look, in your thing, on cluster B, I see you are getting to max, sometimes you can reach 900 I will share it for a moment and show you these are 6 let me make my sharing let me see what is this if it is lost, tell me because the internet is also connected to the internet from morning to evening look, it reaches 900 I can take this up, but it will affect your backend. Now you can get 3000 connections on each of them. On each cluster, you can get 1000 connections. It goes up and down by itself. Now my page is shared. Now it is 437. We will see this one, now we will see it twice, now we will see it on the things, we don't have much connection on the backend, we see it on the client side, our connection goes up towards the application. I don't know now. I will reduce the number of feet, but it is possible to set it to 1200 It will not be a problem on the Kanekin pooling Hello, how are you? I hope you are fine. You are using the Goldchain based API Rw, right? Yes, that's right. Yes This connection utilization of the garage has gone up more than the gold chain. But this picture I sent you, if you look at it, maybe... Which one is Garage? I'm looking at the same cluster, on the 6th proxy. On the 5th. 5 is also on the same cluster as B. Yes. Garage... It has the same thing. It has the same name. Order... The name is... Garage app. Garage app. Garage app. Garage app. It's less now, but in the previous version, when the load was higher, the number of garages was higher than in Gold Chain. Update. 1032. It's possible that garage connections spike suddenly when a lot of drivers are coming online. online and that may be related to I don't know incentives or other push notifications that we might be sending so we should look at that too I think this number of users had an effect on other How is it going? Our lines are getting better in China. Business is also getting better. Our acceptance is returning to its previous state. I just sent a screenshot of a single flight in the same response time, the latency that I had set for the passengers This was a lot Hello, can you share your password? I don't get your meaning. What's your meaning about garage to 100? The number of connections? Yeah, the number of connections for garage is 50, right? So I mean, garage basically, like every time drivers, for example, are going online, garage will probably need more database connections. And this can happen in spikes because like, okay, if we send a push notification or if we have incentive campaign that encourages them to kind of go online at say 9.30 or 10, exactly, and we have seen these kinds of things. So normally they might, I mean, 50 might be enough, but then they might be very spiky, right? And I'm looking at the latency and that increased a lot, like 200, 800 milliseconds, maybe 10, 15 times the normal. So I think garage also, we should increase the connections, the front end connections limit to maybe 100, it is 50 right now. Yeah, you're correct. Let me increase the number of pools as in the upside, but before we need the increment at the DBA side.... because we had an incident where after the requests reached Goldchain, the requests went too far towards the repo and we had lines here now we don't know if it's a broadcast or a problem from the incident itself what I see is that something happened and the load increased and the ideal of the Gold chain was much lower, it didn't reach the maximum but because of the higher load, it was forced to make more connections to the database so that it can handle the load and pull it on the connection and it reached the maximum error there and I saw that the latency was high from the bottom of the path because of this, it was a fact that maybe everyone has more connections to the database like the picture that Yasser gave higher I don't know what the entry was, but I think it was Domino War. In the area of Tehvan, the number of people has increased compared to last week. But in Tehator, the number has decreased. Overall, compared to last week, the number of people is higher, but it's natural. No, we shouldn't cause any problems. Ousain, because of the change you made yesterday and the cities you built in Tehran, you have reduced the number of markets. Isn't it causing any problems? I have a question. Did the launch of the rocket go out of the work? Yes, it did. The End I will update it so that it is not recorded I sent a few messages to the RIPO, and I checked the RIPO's lag, and I think we have this error in the RIPO I think this will help us to solve the problem Yes, it will help us to solve the problem Yes, let me check here again This ephemeral storage request is not a problem The calories are on the kilo Because the ephemeral storage limit is on 100 ml I think they all have the same thing, but it's not a problem if it's a container I think it's a limit, I think containers should be restarted Yesterday we checked on a series of podcasts, I don't remember what service it was on Most of them said they were eating this FM radio and the kids said it's a club Now you want me to check more? Yes How to use FML storage? In this case, the path should not be too long and the file should be stable. Maybe they are sending the log into the container or something like that. I'm going to be on the ground that this happens. Hossein, the last photo that Yasser sent me and Hossein pointed out is the golden SQL timing, it's gone up a lot, its latency Is there any reason that it is not a problem of your database? For example, if you have a problem with the RIPO, how is it? First of all, do you have a service? We first put it in RIPO, then we put it in Colony, then we put it in C-Morgue, Abbas and other services and in the last step we will click on data waste this progress time can help and check to see which one is faster and whichever one is faster that can be root cut but the response is after the ripo and colony correct I will add a point before 9.5 hours the latency was 500ms now it is under 100ms and I think it can clear the root cause for me which part of latency did you talk about? the image I sent is the highest It's a skill timing It was better before The changes you made now made the service better It was because of the lack of feet I did it from 90 feet in the last 4 days to 35 feet I could not do it once, but I did it for a short time to see if it survives on peak timings But now there are 35 offer work and 100 batch matching I mean I have reduced 45 from batch matching And I have reduced 10 from Tehwan, which has more load now These guys have 10 idle connections and they reduce the amount of 1000 connections that are reserved and the proxy is more complex Well, if you don't mind, I'll go back to the recording Thank you Kastan Hafiz Thank you guys, have a nice day Thank you Kastan\"}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6496bbae-344b-4ce9-91bd-2428a4b88fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
