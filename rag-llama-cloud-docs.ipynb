{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b108780-9b6b-4d8c-8960-5d04a2982b5c",
   "metadata": {},
   "source": [
    "## SnappCloud RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4786fe-22ee-48bf-88c1-30aece3783dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install ollama sentence-transformers protobuf tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c9773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install langchain langchain_community chromadb unstructured markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4925d",
   "metadata": {},
   "source": [
    "Ok, now lets do our RAG. Here we can use the cloud resources. If you want to use a local ollama server, you can create a client to localhost:11434 or alternatively just set client = ollama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fee29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollamaBase = 'http://ollama-alibo-gpu-testing.apps.private.okd4.teh-2.snappcloud.io/'\n",
    "ollamaBase = 'http://localhost:11434'\n",
    "import ollama\n",
    "\n",
    "client = ollama.Client(ollamaBase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e46273a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110af750-92dd-405d-88f0-470fbfd0a696",
   "metadata": {},
   "source": [
    "It is expected that the docs directory from snappcloud gitlab documentation is copied and available in the path below\n",
    "\n",
    "Now we fetch all available models on our local/remote GPU instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87789636-20cf-4779-9346-2759b09dbc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llama3:latest', 'mistral:latest', 'mxbai-embed-large:latest', 'tadayuki/suzume-llama3:8b-q4_K_M']\n"
     ]
    }
   ],
   "source": [
    "result = client.list()\n",
    "print([x['name'] for x in result['models']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca04687-83b5-4dbf-982c-0f173f80c103",
   "metadata": {},
   "source": [
    "### Retrieval\n",
    "\n",
    "At this point, we need the cloud docs, which are available on gitlab - https://gitlab.snapp.ir/snappcloud/user-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ce18e1-c4a5-4010-8893-908f9a35981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using existing repo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('./user-docs'):\n",
    "    !git clone https://gitlab.snapp.ir/snappcloud/user-docs\n",
    "else:\n",
    "    print(\"using existing repo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11c64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('./user-docs/docs',glob=\"**/*.md\",loader_cls=UnstructuredMarkdownLoader)\n",
    "embeddingModel = 'mxbai-embed-large'\n",
    "llmModel = 'llama3'\n",
    "systemPrompt = \"You are a helpful assistant that answers questions using the context provided. Cite the relevant documents everytime you provide an answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d06cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user-docs/docs/vpn-access.md', 'user-docs/docs/servicedesk.md', 'user-docs/docs/overview.md', 'user-docs/docs/support.md', 'user-docs/docs/terms.md', 'user-docs/docs/reference/api-documentation.md', 'user-docs/docs/reference/cli-documentation.md', 'user-docs/docs/storage/storage-volumes.md', 'user-docs/docs/storage/volume-snapshots.md', 'user-docs/docs/storage/object-store/aws-s3-sdk.md']\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs = loader.load()\n",
    "print(list(map(lambda x: x.metadata['source'], docs[0:10])))\n",
    "print(len(docs))\n",
    "#print(docs[10].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2675c81",
   "metadata": {},
   "source": [
    "Now we use our embedding model to create the embeddings and store them in chroma. We are using the **mxbai-embed-large** model, whose **context window is 512**, so we must ensure all of our docs are of smaller size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e8e22b2-3361-47bf-982d-3b2afa4b5bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qasim/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=384)\n",
    "splits = token_splitter.split_documents(docs)\n",
    "print(len(splits))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f16b4c2-7f9f-4604-8799-4addd67f0202",
   "metadata": {},
   "source": [
    "What is happening in the split process is something like this, just for reference.\n",
    "token_split_texts = []\n",
    "for text in docs:\n",
    "    token_split_texts += token_splitter.split_text(text.page_content)\n",
    "\n",
    "print(token_split_texts[10])\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f415506-93dc-4728-8bf0-82f9c6ed14ba",
   "metadata": {},
   "source": [
    "We should save the embeddings in a vector db, such as chroma or qdrant. While we are using chroma, you can also change the code to use another one, say quadrant, and langchain will do the abstraction. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaf728a0-df4b-4088-9140-8be59d1a8d2d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "vectorstore = Qdrant.from_documents(documents=docs, embedding=embeddings, path='./quadrant',collection_name='snappcloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e6e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 ms, sys: 4.75 ms, total: 138 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=embeddingModel,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a357be9d-ff4e-43e1-8046-735fa11de984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|███████████████████████| 473/473 [00:44<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.36 s, sys: 265 ms, total: 2.62 s\n",
      "Wall time: 45.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(collection_name='snappcloud',documents=splits, embedding=embeddings,persist_directory='./chromadb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea637ae-eefa-4d2a-91b2-51d446d789ce",
   "metadata": {},
   "source": [
    "Here we just make sure that the number of docs in collection matches the output of split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7592e41-4f58-4fab-8c9b-3f67c65aa457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473\n"
     ]
    }
   ],
   "source": [
    "print(vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061aa222-43a5-4204-ae93-1231740c1157",
   "metadata": {},
   "source": [
    "### Query\n",
    "We can directly query the vectorstore. The quality of RAG is as good as the context provided to llm and no better, \n",
    "and this is one way to see the the context that is being passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0cce086-07a7-4299-abcc-2f646565c01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : cache - proxy title : cache proxy go cache proxy container cache proxy alpine cache proxy npm cache proxy http proxy\n",
      "\n",
      "\n",
      "id : cache - proxy title : cache proxy go cache proxy container cache proxy alpine cache proxy npm cache proxy http proxy\n",
      "\n",
      "\n",
      "local \" the ext _ hostname should be the hostname you are using for exposing your service externally ; the int _ wildcard _ hostname should be a wildcard value for all domains for your project. you can use the following example : for rabbitmq : shell export ext _ hostname = rabbitmq - myproject. apps. private. teh - 1. snappcloud. io export int _ wildcard _ hostname = \" *. rabbitmq. myproject. svc. cluster. local \" for mongodb you will want to use the - internal service name for the int _ wildcard _ hostname : shell export ext _ hostname = mongodb - myproject. apps. private. teh - 1. snappcloud. io export int _ wildcard _ hostname = \" *. mongodb - internal. myproject. svc. cluster. local \" generate the certificates for our root certificate authority : shell cd my - ca openssl req - x509 - config openssl. cnf - newkey rsa : 2048 - days 3650 \\ - out cacert. pem - outform pem - subj / cn = myca / - nodes openssl x509 - in cacert. pem - out cacert. cer - outform der cd.. generate certificates for your required services : for rabbitmq follow this guide for mongodb follow this guide generating certificates for rabbitmq before generating the certificates make sure your ext _ hostname is the correct external domain name you'll be using for your rabbitmq service, e. g. rabbitmq - myproject. apps. private. teh - 1. snappcloud. io generating the server certificate for rabbitm\n",
      "\n",
      "\n",
      "local \" the ext _ hostname should be the hostname you are using for exposing your service externally ; the int _ wildcard _ hostname should be a wildcard value for all domains for your project. you can use the following example : for rabbitmq : shell export ext _ hostname = rabbitmq - myproject. apps. private. teh - 1. snappcloud. io export int _ wildcard _ hostname = \" *. rabbitmq. myproject. svc. cluster. local \" for mongodb you will want to use the - internal service name for the int _ wildcard _ hostname : shell export ext _ hostname = mongodb - myproject. apps. private. teh - 1. snappcloud. io export int _ wildcard _ hostname = \" *. mongodb - internal. myproject. svc. cluster. local \" generate the certificates for our root certificate authority : shell cd my - ca openssl req - x509 - config openssl. cnf - newkey rsa : 2048 - days 3650 \\ - out cacert. pem - outform pem - subj / cn = myca / - nodes openssl x509 - in cacert. pem - out cacert. cer - outform der cd.. generate certificates for your required services : for rabbitmq follow this guide for mongodb follow this guide generating certificates for rabbitmq before generating the certificates make sure your ext _ hostname is the correct external domain name you'll be using for your rabbitmq service, e. g. rabbitmq - myproject. apps. private. teh - 1. snappcloud. io generating the server certificate for rabbitm\n",
      "\n",
      "\n",
      ": vpn access quick start guide - we recommend you start here! introduction to docker cli documentation snappcloud feedback\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the external IPs for snappcloud that i need to whitelist?\"\n",
    "qembed = embeddings.embed_query(query)\n",
    "results = vectorstore._collection.query(query_embeddings = qembed, n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d29048de",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def ollama_llm(question, context):\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = client.chat(model=llmModel, options = { 'temperature': 0}, messages=[{'role': 'system', 'content': systemPrompt},{'role': 'user', 'content': formatted_prompt}])\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64d664db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RAG chain\n",
    "def rag_chain(question):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    print(\"using from context\",list(map(lambda x: x.metadata['source'],retrieved_docs)))\n",
    "    return ollama_llm(question, formatted_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a402c52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using from context ['user-docs/docs/overview.md', 'user-docs/docs/cache-proxy/cache-proxy.md', 'user-docs/docs/management/cli-login.md', 'user-docs/docs/overview.md']\n",
      "To use the Jaeger agent on SnapCloud, you can follow these steps:\n",
      "\n",
      "1. First, make sure you have a Jaeger agent installed in your application. You can do this by adding the following configuration to your `docker-compose.yml` file:\n",
      "```yaml\n",
      "version: '3'\n",
      "services:\n",
      "  jaeger-agent:\n",
      "    image: jaegertracing/jaeger-agent:latest\n",
      "    environment:\n",
      "      - JAEGER_AGENT_HOST=jaeger-agent\n",
      "      - JAEGER_AGENT_PORT=6832\n",
      "```\n",
      "2. Next, you need to configure the Jaeger agent to send its data to SnapCloud's Jaeger instance. You can do this by setting the `JAEGER_COLLECTOR_ENDPOINT` environment variable to point to SnapCloud's Jaeger instance:\n",
      "```yaml\n",
      "version: '3'\n",
      "services:\n",
      "  jaeger-agent:\n",
      "    image: jaegertracing/jaeger-agent:latest\n",
      "    environment:\n",
      "      - JAEGER_AGENT_HOST=jaeger-agent\n",
      "      - JAEGER_AGENT_PORT=6832\n",
      "      - JAEGER_COLLECTOR_ENDPOINT=https://jaeger-collector.snappcloud.com\n",
      "```\n",
      "3. Finally, you need to start the Jaeger agent and make sure it's running in your application:\n",
      "```bash\n",
      "docker-compose up -d jaeger-agent\n",
      "```\n",
      "\n",
      "Please note that you should replace `https://jaeger-collector.snappcloud.com` with the actual endpoint of SnapCloud's Jaeger instance.\n",
      "\n",
      "References:\n",
      "\n",
      "* [Jaeger Agent Configuration](https://www.jaegertracing.io/docs/latest/agent/configuration/)\n",
      "* [SnapCloud Jaeger Instance](https://docs.snappcloud.com/en/snappcloud/jaeger-instance.html)\n",
      "\n",
      "I hope this helps! Let me know if you have any further questions.\n",
      "CPU times: user 66.8 ms, sys: 6.4 ms, total: 73.2 ms\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = rag_chain(\"What address should I use for jaeger agent on snappcloud?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "407b1794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using from context ['user-docs/docs/cache-proxy/cache-proxy.md', 'user-docs/docs/storage/object-store/aws-s3-cli.md', 'user-docs/docs/storage/object-store/overview.md', 'user-docs/docs/learn/creating-self-signed-certificates.md']\n",
      "To whitelist the external IPs for SnapCloud that you need to allowlist, please refer to the following documentation:\n",
      "\n",
      "* [SnapCloud Documentation: External IP Addresses](https://docs.snapcloud.io/docs/external-ip-addresses)\n",
      "\n",
      "According to the documentation, the external IPs for SnapCloud are:\n",
      "\n",
      "* `api.snapcloud.io`\n",
      "* `s3.snapcloud.io`\n",
      "\n",
      "You will need to whitelist these IP addresses in your firewall or security group settings to allow incoming traffic from SnapCloud.\n",
      "\n",
      "Please note that you may also need to whitelist additional IP addresses depending on the specific services and features you are using with SnapCloud.\n",
      "CPU times: user 10.8 ms, sys: 4.27 ms, total: 15.1 ms\n",
      "Wall time: 7.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = rag_chain(\"What are the external IPs for snappcloud that i need to whitelist?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71551df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using from context ['user-docs/docs/management/cli-login.md', 'user-docs/docs/servicedesk.md', 'user-docs/docs/cache-proxy/cache-proxy.md', 'user-docs/docs/overview.md']\n",
      "To increase the quota for your project, follow these steps:\n",
      "\n",
      "1. Go to the Cloud Service Desk page.\n",
      "2. Click on \"Increase OKD Quota\" to create a new ticket.\n",
      "3. Fill in the required fields:\n",
      "\t* Summary: Provide a concise description of your request, including whether the requested resource amount is permanent or temporary.\n",
      "\t* Team Name: Enter the name of the team for which you are requesting resources.\n",
      "\t* Region: Select the appropriate region for your project (TEH-1 or TEH-2).\n",
      "4. Optional additional fields:\n",
      "\t* Additional Memory Limit: If you require additional memory, enter the desired amount in this field.\n",
      "\t* Additional CPU Limit: If you need additional CPU, specify the desired limit in this field.\n",
      "\t* Additional Storage: If you require additional storage, indicate the desired amount in this field.\n",
      "\t* Additional Ephemeral Storage: If you need additional ephemeral storage, enter the desired limit in this field.\n",
      "\t* Additional Pods: If you need additional pods, specify the desired number in this field.\n",
      "\n",
      "Please note that filling out the additional fields is optional, and you do not need to complete all of them.\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain(\"I need to increase the quota for my project, how can I do this?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9181e260-0be7-45ed-837d-ceb18f4de2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7db57-861c-4979-b863-293182394ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
